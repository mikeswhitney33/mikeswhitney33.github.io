<!DOCTYPE HTML>
<html>
	<head>
		<title>Mike Whitney - Portfolio</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- Boot strap Dependencies -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

		<!-- My Style -->
		<link rel="stylesheet" href="/css/style.css">

		<!-- My Script -->
		<script src="/js/script.js"></script>
	</head>
	<body style="background-image:url('/assets/images/bridge.jpg')">
		<div id="topbar"></div>
		<div class="container">

			<div class="row">
				<div class="col-12 project-container">
					<iframe class="project-img d-none d-lg-block" width="560" height="315" src="https://www.youtube-nocookie.com/embed/-h7HnYc4RZQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					<div class="project-body">
						<h5 class="project-title">Multi Person Non Contact Heart Rate Tracking</h5>
						<p class="project-description">
							We implemented a method for detecting heart rates given an input video of one or more faces using a basic web camera for our advanced computer vision class.  This method utilizes <a href='http://people.csail.mit.edu/mrub/vidmag/'> Eulerian video magnification</a>, <a href="https://ieeexplore.ieee.org/document/8360091">multiscale variable-weight Savitzky-Golay combination</a>, and <a href="https://github.com/ageitgey/face_recognition">facial detection and recognition</a>.  Our method is robust to motion and is accurate within ~6 BPM.  Our application was programmed using a cross platform library called <a href="https://kivy.org/#home">Kivy</a> in Python.  This project was done in collaboration with <a href="https://andrewnc.github.io/index.html">Andrew Carr</a>.
						</p>
						<a href="https://youtu.be/-h7HnYc4RZQ" class="btn btn-primary d-lg-none" target="_blank">Demo</a>
					</div>
				</div>
			</div>

			<div class="row">
				<div class="col-12 project-container">
					<iframe class="project-img d-none d-lg-block" width="560" height="315" src="https://www.youtube.com/embed/-tglm5wg6ig" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					<div class="project-body">
						<h5 class="project-title">Face Detection Breakout</h5>
						<p class="project-description">I implemented <a href="https://en.wikipedia.org/wiki/Breakout_(video_game)">Atari's breakout</a> but instead of using the mouse or any buttons for control, I used face detection.  I implemented this entire project using <a href="https://opencv.org">OpenCV</a> in C++.  Source code can be found <a href="https://github.com/mikeswhitney33/FaceDetectionBreakout">here</a>. </p>
						<a href="#" class="btn btn-primary d-lg-none" target="_blank">Demo</a>
					</div>
				</div>
			</div>


		</div>

	</body>
</html>
